{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51de009b-62a0-403f-975d-7b26f3e24ab5",
   "metadata": {},
   "source": [
    "# 1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ba4a081-088f-45b8-96a5-59812b3a9dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from getpass import getpass \n",
    "import sys\n",
    "\n",
    "from langchain_mistralai import ChatMistralAI, MistralAIEmbeddings\n",
    "\n",
    "from operator import itemgetter\n",
    "from typing import Dict, List\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import Runnable, RunnableParallel, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.vectorstores import VectorStore\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from pinecone import Pinecone\n",
    "\n",
    "\n",
    "from pinecone.data.index import Index\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5952296-dc11-44d1-9df6-6b86f7bce447",
   "metadata": {},
   "source": [
    "# 2. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace1d845-9150-45df-b731-f2a07a1f5585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(dotenv_path=\"../../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "89ca3ac2-3e66-4fdf-8ac2-2612cd111b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] =\"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"kn-synthetic-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bc9b1b5-8776-4bc1-b66e-b7e4ad687740",
   "metadata": {},
   "outputs": [],
   "source": [
    "MISTRAL_API_KEY = os.environ[\"MISTRAL_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "78fb3c2f-e86e-42aa-b71a-ab074ad88e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hippolyteleveque/Documents/projects/knowledgenest/backend/venv/lib/python3.11/site-packages/langchain_mistralai/embeddings.py:105: UserWarning: Could not download mistral tokenizer from Huggingface for calculating batch sizes. Set a Huggingface token via the HF_TOKEN environment variable to download the real tokenizer. Falling back to a dummy tokenizer that uses `len()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mistral = ChatMistralAI(model=\"mistral-large-latest\", api_key=MISTRAL_API_KEY)\n",
    "embeddings = MistralAIEmbeddings(model=\"mistral-embed\", api_key=MISTRAL_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352a9cf5-00c7-4a17-acac-b214639c3ccc",
   "metadata": {},
   "source": [
    "### Ingest evaluation sources for RAG if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f5f095d-5127-48fd-97fe-46817a2ed914",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_sources_links = [\n",
    "    \"https://paulgraham.com/foundermode.html\",\n",
    "    \"https://www.paulgraham.com/persistence.html\",\n",
    "    \"https://www.paulgraham.com/reddits.html\",\n",
    "    \"https://www.paulgraham.com/google.html\",\n",
    "    \"https://www.hopsworks.ai/post/mlops-to-ml-systems-with-fti-pipelines\",\n",
    "    \"https://www.palladiummag.com/2024/08/30/when-the-mismanagerial-class-destroys-great-companies/\",\n",
    "]\n",
    "\n",
    "# Collection of short news videos to which the LLM could have had access to when trained. \n",
    "video_sources_links = [\n",
    "    \"https://www.youtube.com/watch?v=8QLVX9A7hqI\",\n",
    "    \"https://www.youtube.com/watch?v=TNc14W8YOuI\",\n",
    "    \"https://www.youtube.com/watch?v=sic0OJyyeZ0\",\n",
    "    \"https://www.youtube.com/watch?v=2HGWuflXCUY\",\n",
    "    \"https://www.youtube.com/watch?v=EDgD7NMY60U\",\n",
    "    \"https://www.youtube.com/watch?v=GUr2AA6ljeU\",\n",
    "    \"https://www.youtube.com/watch?v=DUPH2n3g5bg\",\n",
    "    \"https://www.youtube.com/watch?v=0kOu4GLZRo0\",\n",
    "    \"https://www.youtube.com/watch?v=SsH23u6XiGY\",\n",
    "    \"https://www.youtube.com/watch?v=rvu8N6bA3PI\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a30daa09-5caf-4b34-9cd4-febdd96929ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders.web_base import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24a38422-e86f-4e4d-91ff-1c14a31a3be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_article(url):\n",
    "    \"\"\"Load article and extract text content\"\"\"\n",
    "    loader = WebBaseLoader(\n",
    "        web_paths=(str(url),),\n",
    "    )\n",
    "    docs = loader.load()\n",
    "    return docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2995f4c5-55ab-459e-bbf1-57595bec365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b0328d5-fae9-44fe-b93e-3d87151157f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = dict()\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = {executor.submit(load_article, url): url for url in articles_sources_links}\n",
    "    for res in as_completed(futures):\n",
    "        url = futures[res]\n",
    "        articles[url] = res.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d538f87-0b9c-45d2-a147-c50d902576d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bff5223-3d18-46ce-a830-c6b114f90b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(url):\n",
    "    \"\"\"Load video and extract text transcript\"\"\"\n",
    "    loader = YoutubeLoader.from_youtube_url(url, add_video_info=False)\n",
    "    docs = loader.load()\n",
    "    return docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19c02c07-0cf3-4fad-9cf0-3dde27f98924",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = dict()\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = {executor.submit(load_video, url): url for url in video_sources_links}\n",
    "    for res in as_completed(futures):\n",
    "        url = futures[res]\n",
    "        videos[url] = res.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6d1200-815f-415a-81bc-1994c865333c",
   "metadata": {},
   "source": [
    "# 4. Evals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e23fcf1-6266-490d-a0cd-7db94d5d914e",
   "metadata": {},
   "source": [
    "### A. Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b333d36d-1474-430d-8a73-0aaa76070290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "406bf150-f475-4686-889b-33f8442dd364",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticQAPair(BaseModel):\n",
    "    \"\"\"A QA Pair for a specific document\"\"\"\n",
    "\n",
    "    question: str = Field(..., description=\"A question which answers lies in the document, should be precise and be completely answered with the document\")\n",
    "    answer: str = Field(..., description=\"The answer expected from the question, only reformulating material from the document\")\n",
    "\n",
    "class SyntheticQAPairs(BaseModel):\n",
    "    \"\"\"A list of QA pairs from a specific document\"\"\"\n",
    "    pairs: List[SyntheticQAPair] = Field(..., description=\"A list of question / answer pair extracted from the document, always includes between 2 and 5 pairs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6101e5a9-a028-4eba-811f-daaa2021945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8ef32dc7-c457-44c1-8da7-052edde65b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_document_pairs(document):\n",
    "    instructions = \"\"\"\n",
    "                You are an expert teacher tasked with generating question/answer pairs for an exam.\n",
    "                You are given a document and your goal is to create meaningful and relevant questions \n",
    "                that can be answered using material contained in the document.\n",
    "\n",
    "                Instructions:\n",
    "                \n",
    "                Read the entire document carefully to understand its content and context.\n",
    "                Identify key points and significant information within the document, don't focus too much on details.\n",
    "                Generate a set of questions that are directly answerable using the information from the document.\n",
    "                Ensure that each question has an interest that extends beyond the scope of this document, yet can be\n",
    "                answered from the document.\n",
    "                For each question, provide a corresponding answer that is accurate and concise.\n",
    "                Ensure that the questions are varied in nature, covering different aspects of the document.\n",
    "                Avoid creating questions that require external knowledge or information not present in the document.\n",
    "                \n",
    "                Your Task:\n",
    "                \n",
    "                Generate a set of question/answer pairs based on the following document: \\n\\n{document}\n",
    "            \"\"\"\n",
    "    prompt = PromptTemplate.from_template(instructions)\n",
    "    llm = mistral.with_structured_output(SyntheticQAPairs)\n",
    "    chain = prompt | llm \n",
    "    return chain.invoke(dict(document=document))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ac168bd4-a6ff-4084-af6b-fc95787f31f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pairs = []\n",
    "\n",
    "for article in articles.values():\n",
    "    pairs = generate_document_pairs(article)\n",
    "    qa_pairs.extend(pairs)\n",
    "\n",
    "for video in videos.values():\n",
    "    pairs = generate_document_pairs(video)\n",
    "    qa_pairs.extend(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a1ac8823-d24f-4ac9-a1df-40f79724df30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qa_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e3bb9de9-d0af-41e1-9110-f97f58b073c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pairs = [pair for pairs in qa_pairs for pair in pairs[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "239c3138-29a0-4abe-8cb2-eeb637c940b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "from langsmith.evaluation import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "10da04c2-845a-4f82-afaa-5181ee7077f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()\n",
    "base_dataset_name = \"kn-eval-synthetic-qa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "418f0700-84d7-44f6-ae16-011a7ad1badf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = base_dataset_name + \"-v0\"\n",
    "datasets = client.list_datasets(dataset_name=dataset_name)\n",
    "try:\n",
    "    next(datasets) # dataset already exists\n",
    "    print(f\"Dataset {dataset_name} already exists\")\n",
    "    pass\n",
    "except StopIteration:\n",
    "    # dataset does not exist\n",
    "    dataset = client.create_dataset(\n",
    "        dataset_name=dataset_name,\n",
    "        description=\"Synthetic QA pairs for evaluation of RAG KN\",\n",
    "    )\n",
    "    client.create_examples(\n",
    "        inputs=[{\"question\": p.question} for p in true_pairs],\n",
    "        outputs=[{\"answer\": p.answer} for p in true_pairs],\n",
    "        dataset_id=dataset.id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5496384e-5f79-4506-b54d-5d6e2ff98ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knowledgenest",
   "language": "python",
   "name": "knowledgenest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
